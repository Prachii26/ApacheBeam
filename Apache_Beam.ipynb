{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR7w5I7OeIu6FoM602ajud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prachii26/ApacheBeam/blob/main/Apache_Beam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment\n",
        "###Submitted By: Prachi Gupta\n",
        "###SJSU ID: 019106594"
      ],
      "metadata": {
        "id": "_Dct3qwTGQdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7DjTV9nfm22",
        "outputId": "faf324bf-ea8a-4f83-f2d8-70995fc48aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Setup complete\n",
            "Python:        3.12.12\n",
            "Apache Beam:   2.68.0\n",
            "Interactive:   True\n",
            "BASE_DIR:      /content/beam_demo\n",
            "DATA_DIR:      /content/beam_demo/data\n",
            "OUT_DIR:       /content/beam_demo/out\n"
          ]
        }
      ],
      "source": [
        "# === Cell 1: Environment setup for Apache Beam demo (Colab) ===================\n",
        "# Install required packages\n",
        "!pip -q install --upgrade apache-beam scikit-learn\n",
        "\n",
        "# --- Imports & basic config\n",
        "import os, sys, platform, random\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "# Reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Project directories (local to Colab)\n",
        "BASE_DIR = \"/content/beam_demo\"\n",
        "DATA_DIR = f\"{BASE_DIR}/data\"\n",
        "OUT_DIR  = f\"{BASE_DIR}/out\"\n",
        "for d in (BASE_DIR, DATA_DIR, OUT_DIR):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# Try to enable Interactive Beam (nice for inspecting PCollections in notebooks)\n",
        "try:\n",
        "    from apache_beam.runners.interactive import interactive_beam as ib\n",
        "    ib.watch(locals())\n",
        "    INTERACTIVE_READY = True\n",
        "except Exception:\n",
        "    INTERACTIVE_READY = False  # It's ok if this isn't available\n",
        "\n",
        "# Default to DirectRunner (local)\n",
        "beam_options = PipelineOptions([\"--runner=DirectRunner\"])\n",
        "\n",
        "# Helper: clean output directory between runs (we'll use this later)\n",
        "def reset_out_dir():\n",
        "    import shutil\n",
        "    if os.path.exists(OUT_DIR):\n",
        "        shutil.rmtree(OUT_DIR)\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Summary printout\n",
        "print(\"✅ Setup complete\")\n",
        "print(f\"Python:        {platform.python_version()}\")\n",
        "print(f\"Apache Beam:   {beam.__version__}\")\n",
        "print(f\"Interactive:   {INTERACTIVE_READY}\")\n",
        "print(f\"BASE_DIR:      {BASE_DIR}\")\n",
        "print(f\"DATA_DIR:      {DATA_DIR}\")\n",
        "print(f\"OUT_DIR:       {OUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: Create a small synthetic dataset (transactions.csv) ==============\n",
        "# Columns: event_time (ISO8601), user_id, amount, category\n",
        "# We'll treat event_time as the event timestamp later for windowing.\n",
        "\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import os, random\n",
        "\n",
        "# Make results reproducible\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "N = 200  # number of rows\n",
        "categories = [\"grocery\", \"electronics\", \"fashion\", \"travel\", \"utilities\", \"other\"]\n",
        "\n",
        "start_time = datetime.utcnow() - timedelta(minutes=10)\n",
        "times = []\n",
        "t = start_time\n",
        "for i in range(N):\n",
        "    # irregular gaps between 1-20 seconds to make windows interesting\n",
        "    t += timedelta(seconds=random.randint(1, 20))\n",
        "    times.append(t)\n",
        "\n",
        "user_ids = np.random.randint(1, 31, size=N)  # 30 users\n",
        "# positive skew for amounts; clamp to [1, 500]\n",
        "amounts = np.clip(np.random.lognormal(mean=2.5, sigma=0.8, size=N), 1, 500)\n",
        "cats = np.random.choice(categories, size=N, p=[0.25,0.15,0.2,0.15,0.15,0.1])\n",
        "\n",
        "csv_path = os.path.join(DATA_DIR, \"transactions.csv\")\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"event_time\",\"user_id\",\"amount\",\"category\"])\n",
        "    for ts, uid, amt, cat in zip(times, user_ids, amounts, cats):\n",
        "        w.writerow([ts.isoformat() + \"Z\", int(uid), round(float(amt), 2), cat])\n",
        "\n",
        "# Quick preview: show first 5 lines\n",
        "print(f\"✅ Wrote {N} rows to: {csv_path}\")\n",
        "with open(csv_path, \"r\") as f:\n",
        "    head = [next(f).strip() for _ in range(6)]  # header + 5 rows\n",
        "print(\"\\n\".join(head))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IopU7pULftSo",
        "outputId": "515cbb4f-bc93-4f32-8522-f1ad14a331fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote 200 rows to: /content/beam_demo/data/transactions.csv\n",
            "event_time,user_id,amount,category\n",
            "2025-10-22T20:18:39.113498Z,7,24.49,grocery\n",
            "2025-10-22T20:18:40.113498Z,20,75.93,utilities\n",
            "2025-10-22T20:18:49.113498Z,29,44.63,utilities\n",
            "2025-10-22T20:18:57.113498Z,15,23.55,travel\n",
            "2025-10-22T20:19:05.113498Z,11,15.4,utilities\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3980964974.py:17: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  start_time = datetime.utcnow() - timedelta(minutes=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Read CSV -> Map/Filter -> Write JSONL ============================\n",
        "# Demonstrates: Pipeline I/O (ReadFromText, WriteToText), Map, Filter\n",
        "\n",
        "import os, json, csv, glob\n",
        "import apache_beam as beam\n",
        "\n",
        "reset_out_dir()  # from Cell 1\n",
        "\n",
        "INPUT_CSV = os.path.join(DATA_DIR, \"transactions.csv\")\n",
        "OUT_SUBDIR = os.path.join(OUT_DIR, \"01_parsed\")\n",
        "os.makedirs(OUT_SUBDIR, exist_ok=True)\n",
        "OUT_PREFIX = os.path.join(OUT_SUBDIR, \"transactions\")\n",
        "\n",
        "def parse_line(line: str):\n",
        "    # Robust CSV parsing for a single line\n",
        "    row = next(csv.reader([line]))\n",
        "    event_time, user_id, amount, category = row\n",
        "    return {\n",
        "        \"event_time\": event_time,\n",
        "        \"user_id\": int(user_id),\n",
        "        \"amount\": float(amount),\n",
        "        \"category\": category\n",
        "    }\n",
        "\n",
        "def is_valid(rec: dict) -> bool:\n",
        "    return rec[\"user_id\"] > 0 and rec[\"amount\"] > 0.0 and rec[\"category\"] != \"\"\n",
        "\n",
        "with beam.Pipeline(options=beam_options) as p:\n",
        "    _ = (\n",
        "        p\n",
        "        # skip_header_lines avoids manual header filtering\n",
        "        | \"ReadCSV\" >> beam.io.ReadFromText(INPUT_CSV, skip_header_lines=1)\n",
        "        | \"ParseCSV\" >> beam.Map(parse_line)          # Map\n",
        "        | \"FilterInvalid\" >> beam.Filter(is_valid)    # Filter\n",
        "        | \"ToJSON\" >> beam.Map(json.dumps)\n",
        "        | \"WriteJSONL\" >> beam.io.WriteToText(\n",
        "            OUT_PREFIX, file_name_suffix=\".jsonl\", num_shards=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Preview a few output lines\n",
        "out_files = sorted(glob.glob(os.path.join(OUT_SUBDIR, \"transactions-*.jsonl\")))\n",
        "print(f\"✅ Wrote parsed data to: {out_files[0] if out_files else '(none)'}\")\n",
        "if out_files:\n",
        "    with open(out_files[0], \"r\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 5: break\n",
        "            print(line.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N-Mxc0ggzlR",
        "outputId": "f0a0b027-a22f-4a4e-8806-60c8007af944"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote parsed data to: /content/beam_demo/out/01_parsed/transactions-00000-of-00001.jsonl\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\"}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\"}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\"}\n",
            "{\"event_time\": \"2025-10-22T20:18:57.113498Z\", \"user_id\": 15, \"amount\": 23.55, \"category\": \"travel\"}\n",
            "{\"event_time\": \"2025-10-22T20:19:05.113498Z\", \"user_id\": 11, \"amount\": 15.4, \"category\": \"utilities\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: ParDo (DoFn) + Composite transform ===============================\n",
        "# Demonstrates: ParDo via a custom DoFn, and a Composite PTransform\n",
        "# Input: transactions.csv\n",
        "# Output: enriched JSONL in OUT_DIR/02_enriched\n",
        "\n",
        "import os, json, csv, glob\n",
        "from typing import Dict, Iterable\n",
        "import apache_beam as beam\n",
        "\n",
        "INPUT_CSV = os.path.join(DATA_DIR, \"transactions.csv\")\n",
        "OUT_SUBDIR = os.path.join(OUT_DIR, \"02_enriched\")\n",
        "os.makedirs(OUT_SUBDIR, exist_ok=True)\n",
        "OUT_PREFIX = os.path.join(OUT_SUBDIR, \"transactions_enriched\")\n",
        "\n",
        "# --- Re-define parse/validate for self-contained execution in this cell -------\n",
        "def parse_line(line: str) -> Dict:\n",
        "    row = next(csv.reader([line]))\n",
        "    event_time, user_id, amount, category = row\n",
        "    return {\n",
        "        \"event_time\": event_time,\n",
        "        \"user_id\": int(user_id),\n",
        "        \"amount\": float(amount),\n",
        "        \"category\": category,\n",
        "    }\n",
        "\n",
        "def is_valid(rec: Dict) -> bool:\n",
        "    return rec[\"user_id\"] > 0 and rec[\"amount\"] > 0.0 and rec[\"category\"] != \"\"\n",
        "\n",
        "# --- ParDo: enrich each record with derived features --------------------------\n",
        "class EnrichDoFn(beam.DoFn):\n",
        "    def process(self, rec: Dict) -> Iterable[Dict]:\n",
        "        rec = dict(rec)  # shallow copy to avoid mutating input\n",
        "        amt = rec.get(\"amount\", 0.0)\n",
        "\n",
        "        # Simple tiering logic based on amount\n",
        "        if amt >= 200:\n",
        "            tier = \"vip\"\n",
        "        elif amt >= 100:\n",
        "            tier = \"high\"\n",
        "        elif amt >= 50:\n",
        "            tier = \"med\"\n",
        "        else:\n",
        "            tier = \"low\"\n",
        "        rec[\"amount_tier\"] = tier\n",
        "\n",
        "        # Normalize and add a user hash bucket (0..9) for later partitioning\n",
        "        rec[\"category\"] = str(rec.get(\"category\", \"\")).strip().lower()\n",
        "        rec[\"user_bucket\"] = int(rec[\"user_id\"]) % 10\n",
        "\n",
        "        # Example boolean flag\n",
        "        rec[\"is_high_value\"] = amt >= 100.0\n",
        "\n",
        "        yield rec\n",
        "\n",
        "# --- Composite transform: parse -> validate -> enrich -------------------------\n",
        "class ParseValidateEnrich(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | \"ParseCSV\" >> beam.Map(parse_line)\n",
        "            | \"FilterInvalid\" >> beam.Filter(is_valid)\n",
        "            | \"Enrich\" >> beam.ParDo(EnrichDoFn())\n",
        "        )\n",
        "\n",
        "# --- Run pipeline -------------------------------------------------------------\n",
        "with beam.Pipeline(options=beam_options) as p:\n",
        "    lines = p | \"ReadCSV\" >> beam.io.ReadFromText(INPUT_CSV, skip_header_lines=1)\n",
        "    enriched = lines | \"PVE\" >> ParseValidateEnrich()\n",
        "    _ = (\n",
        "        enriched\n",
        "        | \"ToJSON\" >> beam.Map(json.dumps)\n",
        "        | \"WriteJSONL\" >> beam.io.WriteToText(\n",
        "            OUT_PREFIX, file_name_suffix=\".jsonl\", num_shards=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Preview output\n",
        "out_files = sorted(glob.glob(os.path.join(OUT_SUBDIR, \"transactions_enriched-*.jsonl\")))\n",
        "print(f\"✅ Enriched output: {out_files[0] if out_files else '(none)'}\")\n",
        "if out_files:\n",
        "    with open(out_files[0], \"r\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 5: break\n",
        "            print(line.strip())\n"
      ],
      "metadata": {
        "id": "e1_zTBHljdGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8c5e7f-5ca1-4287-e722-eb5c711445fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Enriched output: /content/beam_demo/out/02_enriched/transactions_enriched-00000-of-00001.jsonl\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\", \"amount_tier\": \"low\", \"user_bucket\": 7, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\", \"amount_tier\": \"med\", \"user_bucket\": 0, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\", \"amount_tier\": \"low\", \"user_bucket\": 9, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:57.113498Z\", \"user_id\": 15, \"amount\": 23.55, \"category\": \"travel\", \"amount_tier\": \"low\", \"user_bucket\": 5, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:19:05.113498Z\", \"user_id\": 11, \"amount\": 15.4, \"category\": \"utilities\", \"amount_tier\": \"low\", \"user_bucket\": 1, \"is_high_value\": false}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5: Partition (high_value vs regular) ================================\n",
        "# Demonstrates: beam.Partition\n",
        "# Input: OUT_DIR/02_enriched/transactions_enriched-*.jsonl (from Cell 4)\n",
        "# Output: OUT_DIR/03_partition/{high_value|regular}-*.jsonl\n",
        "\n",
        "import os, json, glob\n",
        "import apache_beam as beam\n",
        "\n",
        "# Locate enriched input from previous cell\n",
        "ENRICHED_DIR = os.path.join(OUT_DIR, \"02_enriched\")\n",
        "enriched_files = sorted(glob.glob(os.path.join(ENRICHED_DIR, \"transactions_enriched-*.jsonl\")))\n",
        "assert enriched_files, \"No enriched files found. Please run Cell 4 first.\"\n",
        "INPUT_ENRICHED = enriched_files[0]\n",
        "\n",
        "# Output paths\n",
        "OUT_SUBDIR = os.path.join(OUT_DIR, \"03_partition\")\n",
        "os.makedirs(OUT_SUBDIR, exist_ok=True)\n",
        "OUT_PREFIX_HIGH = os.path.join(OUT_SUBDIR, \"high_value\")\n",
        "OUT_PREFIX_REG  = os.path.join(OUT_SUBDIR, \"regular\")\n",
        "\n",
        "def to_obj(line: str):\n",
        "    return json.loads(line)\n",
        "\n",
        "def partition_by_value(rec, n_partitions):\n",
        "    # 0 -> high_value, 1 -> regular\n",
        "    return 0 if rec.get(\"is_high_value\", False) else 1\n",
        "\n",
        "with beam.Pipeline(options=beam_options) as p:\n",
        "    objs = (\n",
        "        p\n",
        "        | \"ReadEnriched\" >> beam.io.ReadFromText(INPUT_ENRICHED)\n",
        "        | \"ParseJSON\"    >> beam.Map(to_obj)\n",
        "    )\n",
        "\n",
        "    parts = objs | \"PartitionHighRegular\" >> beam.Partition(partition_by_value, 2)\n",
        "\n",
        "    high = parts[0]\n",
        "    reg  = parts[1]\n",
        "\n",
        "    _ = (\n",
        "        high\n",
        "        | \"HighToJSON\" >> beam.Map(json.dumps)\n",
        "        | \"WriteHigh\"  >> beam.io.WriteToText(OUT_PREFIX_HIGH, file_name_suffix=\".jsonl\", num_shards=1)\n",
        "    )\n",
        "    _ = (\n",
        "        reg\n",
        "        | \"RegToJSON\" >> beam.Map(json.dumps)\n",
        "        | \"WriteReg\"  >> beam.io.WriteToText(OUT_PREFIX_REG, file_name_suffix=\".jsonl\", num_shards=1)\n",
        "    )\n",
        "\n",
        "# Preview & simple counts\n",
        "high_file = sorted(glob.glob(os.path.join(OUT_SUBDIR, \"high_value-*.jsonl\")))[0]\n",
        "reg_file  = sorted(glob.glob(os.path.join(OUT_SUBDIR, \"regular-*.jsonl\")))[0]\n",
        "\n",
        "def count_lines(path):\n",
        "    c = 0\n",
        "    with open(path, \"r\") as f:\n",
        "        for _ in f:\n",
        "            c += 1\n",
        "    return c\n",
        "\n",
        "print(\"✅ Partition complete\")\n",
        "print(f\"High-value file: {high_file} (records: {count_lines(high_file)})\")\n",
        "print(f\"Regular  file:   {reg_file}  (records: {count_lines(reg_file)})\")\n",
        "\n",
        "# Show a couple of examples from each\n",
        "print(\"\\n-- High-value sample --\")\n",
        "with open(high_file, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 3: break\n",
        "        print(line.strip())\n",
        "\n",
        "print(\"\\n-- Regular sample --\")\n",
        "with open(reg_file, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 3: break\n",
        "        print(line.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wrZiR3nNGpy",
        "outputId": "17da872e-6676-407f-8474-df51598426e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Partition complete\n",
            "High-value file: /content/beam_demo/out/03_partition/high_value-00000-of-00001.jsonl (records: 3)\n",
            "Regular  file:   /content/beam_demo/out/03_partition/regular-00000-of-00001.jsonl  (records: 197)\n",
            "\n",
            "-- High-value sample --\n",
            "{\"event_time\": \"2025-10-22T20:21:50.113498Z\", \"user_id\": 21, \"amount\": 128.37, \"category\": \"other\", \"amount_tier\": \"high\", \"user_bucket\": 1, \"is_high_value\": true}\n",
            "{\"event_time\": \"2025-10-22T20:34:26.113498Z\", \"user_id\": 26, \"amount\": 141.02, \"category\": \"travel\", \"amount_tier\": \"high\", \"user_bucket\": 6, \"is_high_value\": true}\n",
            "{\"event_time\": \"2025-10-22T20:37:03.113498Z\", \"user_id\": 25, \"amount\": 112.97, \"category\": \"fashion\", \"amount_tier\": \"high\", \"user_bucket\": 5, \"is_high_value\": true}\n",
            "\n",
            "-- Regular sample --\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\", \"amount_tier\": \"low\", \"user_bucket\": 7, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\", \"amount_tier\": \"med\", \"user_bucket\": 0, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\", \"amount_tier\": \"low\", \"user_bucket\": 9, \"is_high_value\": false}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: Windowing with event time ================================\n",
        "# Uses TimestampedValue instead of beam.WithTimestamps\n",
        "\n",
        "import os, json, glob\n",
        "from datetime import datetime\n",
        "import apache_beam as beam\n",
        "from apache_beam.transforms import window as beam_window\n",
        "\n",
        "# Locate enriched input\n",
        "ENRICHED_DIR = os.path.join(OUT_DIR, \"02_enriched\")\n",
        "enriched_files = sorted(glob.glob(os.path.join(ENRICHED_DIR, \"transactions_enriched-*.jsonl\")))\n",
        "assert enriched_files, \"No enriched files found. Please run Cell 4 first.\"\n",
        "INPUT_ENRICHED = enriched_files[0]\n",
        "\n",
        "# Output path\n",
        "OUT_SUBDIR = os.path.join(OUT_DIR, \"04_windowed\")\n",
        "os.makedirs(OUT_SUBDIR, exist_ok=True)\n",
        "OUT_PREFIX = os.path.join(OUT_SUBDIR, \"windowed\")\n",
        "\n",
        "def to_obj(line: str):\n",
        "    return json.loads(line)\n",
        "\n",
        "def parse_event_ts(rec):\n",
        "    # Convert ISO8601 '...Z' to timezone-aware and return epoch seconds (float)\n",
        "    s = rec[\"event_time\"]\n",
        "    if s.endswith(\"Z\"):\n",
        "        s = s[:-1] + \"+00:00\"\n",
        "    dt = datetime.fromisoformat(s)\n",
        "    return dt.timestamp()\n",
        "\n",
        "def add_timestamp(rec):\n",
        "    # Attach event-time timestamp to each record\n",
        "    return beam.window.TimestampedValue(rec, parse_event_ts(rec))\n",
        "\n",
        "class FormatWindowedDoFn(beam.DoFn):\n",
        "    def process(self, kv, window=beam.DoFn.WindowParam):\n",
        "        category, total = kv\n",
        "        ws = window.start.to_utc_datetime().isoformat()\n",
        "        we = window.end.to_utc_datetime().isoformat()\n",
        "        yield json.dumps({\n",
        "            \"window_start\": ws,\n",
        "            \"window_end\": we,\n",
        "            \"category\": category,\n",
        "            \"total_amount\": round(float(total), 2),\n",
        "        })\n",
        "\n",
        "with beam.Pipeline(options=beam_options) as p:\n",
        "    _ = (\n",
        "        p\n",
        "        | \"ReadEnriched\" >> beam.io.ReadFromText(INPUT_ENRICHED)\n",
        "        | \"ParseJSON\"    >> beam.Map(to_obj)\n",
        "        | \"AddTimestamps\" >> beam.Map(add_timestamp)                           # event time\n",
        "        | \"FixedWindows60s\" >> beam.WindowInto(beam_window.FixedWindows(60))   # windowing\n",
        "        | \"ToKV\" >> beam.Map(lambda rec: (rec[\"category\"], rec[\"amount\"]))\n",
        "        | \"SumPerCategoryPerWindow\" >> beam.CombinePerKey(sum)\n",
        "        | \"FormatWindowed\" >> beam.ParDo(FormatWindowedDoFn())\n",
        "        | \"WriteWindowed\" >> beam.io.WriteToText(OUT_PREFIX, file_name_suffix=\".jsonl\", num_shards=1)\n",
        "    )\n",
        "\n",
        "# Preview a few windowed results\n",
        "out_files = sorted(glob.glob(os.path.join(OUT_SUBDIR, \"windowed-*.jsonl\")))\n",
        "print(f\"✅ Windowing complete. Output: {out_files[0] if out_files else '(none)'}\")\n",
        "if out_files:\n",
        "    with open(out_files[0], \"r\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 10: break\n",
        "            print(line.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEHXemC8OvoO",
        "outputId": "e65460ba-be64-4bc0-8598-d0bb42ad356a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Windowing complete. Output: /content/beam_demo/out/04_windowed/windowed-00000-of-00001.jsonl\n",
            "{\"window_start\": \"2025-10-22T20:18:00\", \"window_end\": \"2025-10-22T20:19:00\", \"category\": \"grocery\", \"total_amount\": 24.49}\n",
            "{\"window_start\": \"2025-10-22T20:19:00\", \"window_end\": \"2025-10-22T20:20:00\", \"category\": \"grocery\", \"total_amount\": 11.2}\n",
            "{\"window_start\": \"2025-10-22T20:20:00\", \"window_end\": \"2025-10-22T20:21:00\", \"category\": \"grocery\", \"total_amount\": 26.31}\n",
            "{\"window_start\": \"2025-10-22T20:22:00\", \"window_end\": \"2025-10-22T20:23:00\", \"category\": \"grocery\", \"total_amount\": 5.07}\n",
            "{\"window_start\": \"2025-10-22T20:23:00\", \"window_end\": \"2025-10-22T20:24:00\", \"category\": \"grocery\", \"total_amount\": 6.19}\n",
            "{\"window_start\": \"2025-10-22T20:24:00\", \"window_end\": \"2025-10-22T20:25:00\", \"category\": \"grocery\", \"total_amount\": 27.36}\n",
            "{\"window_start\": \"2025-10-22T20:25:00\", \"window_end\": \"2025-10-22T20:26:00\", \"category\": \"grocery\", \"total_amount\": 11.37}\n",
            "{\"window_start\": \"2025-10-22T20:27:00\", \"window_end\": \"2025-10-22T20:28:00\", \"category\": \"grocery\", \"total_amount\": 34.65}\n",
            "{\"window_start\": \"2025-10-22T20:28:00\", \"window_end\": \"2025-10-22T20:29:00\", \"category\": \"grocery\", \"total_amount\": 39.94}\n",
            "{\"window_start\": \"2025-10-22T20:30:00\", \"window_end\": \"2025-10-22T20:31:00\", \"category\": \"grocery\", \"total_amount\": 27.12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7: Notebook index + validation =====================================\n",
        "# Summarizes what we've built, verifies outputs exist, and shows quick samples.\n",
        "\n",
        "import os, glob, json, textwrap\n",
        "\n",
        "def count_lines(path):\n",
        "    c = 0\n",
        "    with open(path, \"r\") as f:\n",
        "        for _ in f: c += 1\n",
        "    return c\n",
        "\n",
        "def show_head(path, n=3):\n",
        "    rows = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= n: break\n",
        "            rows.append(line.strip())\n",
        "    return rows\n",
        "\n",
        "# Locate artifacts from previous cells\n",
        "artifacts = {\n",
        "    \"parsed\": sorted(glob.glob(os.path.join(OUT_DIR, \"01_parsed\", \"transactions-*.jsonl\"))),\n",
        "    \"enriched\": sorted(glob.glob(os.path.join(OUT_DIR, \"02_enriched\", \"transactions_enriched-*.jsonl\"))),\n",
        "    \"high_value\": sorted(glob.glob(os.path.join(OUT_DIR, \"03_partition\", \"high_value-*.jsonl\"))),\n",
        "    \"regular\": sorted(glob.glob(os.path.join(OUT_DIR, \"03_partition\", \"regular-*.jsonl\"))),\n",
        "    \"windowed\": sorted(glob.glob(os.path.join(OUT_DIR, \"04_windowed\", \"windowed-*.jsonl\"))),\n",
        "}\n",
        "\n",
        "print(\"✅ Artifact check\")\n",
        "for key, files in artifacts.items():\n",
        "    if files:\n",
        "        p = files[0]\n",
        "        print(f\" - {key:10s}: {p}  (records: {count_lines(p)})\")\n",
        "    else:\n",
        "        print(f\" - {key:10s}: MISSING (run the earlier cell for this stage)\")\n",
        "\n",
        "# Show a few sample lines from each available artifact\n",
        "print(\"\\n🔎 Samples (first 3 lines each):\")\n",
        "for key in [\"parsed\", \"enriched\", \"high_value\", \"regular\", \"windowed\"]:\n",
        "    files = artifacts[key]\n",
        "    if not files:\n",
        "        continue\n",
        "    p = files[0]\n",
        "    print(f\"\\n--- {key.upper()} ---\")\n",
        "    for line in show_head(p, n=3):\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocpMgNwjQnlx",
        "outputId": "d10e1b29-3edc-49b1-b228-6a597259c23d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Artifact check\n",
            " - parsed    : /content/beam_demo/out/01_parsed/transactions-00000-of-00001.jsonl  (records: 200)\n",
            " - enriched  : /content/beam_demo/out/02_enriched/transactions_enriched-00000-of-00001.jsonl  (records: 200)\n",
            " - high_value: /content/beam_demo/out/03_partition/high_value-00000-of-00001.jsonl  (records: 3)\n",
            " - regular   : /content/beam_demo/out/03_partition/regular-00000-of-00001.jsonl  (records: 197)\n",
            " - windowed  : /content/beam_demo/out/04_windowed/windowed-00000-of-00001.jsonl  (records: 130)\n",
            "\n",
            "🔎 Samples (first 3 lines each):\n",
            "\n",
            "--- PARSED ---\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\"}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\"}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\"}\n",
            "\n",
            "--- ENRICHED ---\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\", \"amount_tier\": \"low\", \"user_bucket\": 7, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\", \"amount_tier\": \"med\", \"user_bucket\": 0, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\", \"amount_tier\": \"low\", \"user_bucket\": 9, \"is_high_value\": false}\n",
            "\n",
            "--- HIGH_VALUE ---\n",
            "{\"event_time\": \"2025-10-22T20:21:50.113498Z\", \"user_id\": 21, \"amount\": 128.37, \"category\": \"other\", \"amount_tier\": \"high\", \"user_bucket\": 1, \"is_high_value\": true}\n",
            "{\"event_time\": \"2025-10-22T20:34:26.113498Z\", \"user_id\": 26, \"amount\": 141.02, \"category\": \"travel\", \"amount_tier\": \"high\", \"user_bucket\": 6, \"is_high_value\": true}\n",
            "{\"event_time\": \"2025-10-22T20:37:03.113498Z\", \"user_id\": 25, \"amount\": 112.97, \"category\": \"fashion\", \"amount_tier\": \"high\", \"user_bucket\": 5, \"is_high_value\": true}\n",
            "\n",
            "--- REGULAR ---\n",
            "{\"event_time\": \"2025-10-22T20:18:39.113498Z\", \"user_id\": 7, \"amount\": 24.49, \"category\": \"grocery\", \"amount_tier\": \"low\", \"user_bucket\": 7, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:40.113498Z\", \"user_id\": 20, \"amount\": 75.93, \"category\": \"utilities\", \"amount_tier\": \"med\", \"user_bucket\": 0, \"is_high_value\": false}\n",
            "{\"event_time\": \"2025-10-22T20:18:49.113498Z\", \"user_id\": 29, \"amount\": 44.63, \"category\": \"utilities\", \"amount_tier\": \"low\", \"user_bucket\": 9, \"is_high_value\": false}\n",
            "\n",
            "--- WINDOWED ---\n",
            "{\"window_start\": \"2025-10-22T20:18:00\", \"window_end\": \"2025-10-22T20:19:00\", \"category\": \"grocery\", \"total_amount\": 24.49}\n",
            "{\"window_start\": \"2025-10-22T20:19:00\", \"window_end\": \"2025-10-22T20:20:00\", \"category\": \"grocery\", \"total_amount\": 11.2}\n",
            "{\"window_start\": \"2025-10-22T20:20:00\", \"window_end\": \"2025-10-22T20:21:00\", \"category\": \"grocery\", \"total_amount\": 26.31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8UZSE_NWQIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}